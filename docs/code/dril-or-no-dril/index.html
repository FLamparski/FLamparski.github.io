<!doctype html>
<html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Dril Or No Dril? Building a text classifier in TensorFlow - Code - Filip Wieland</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content=""><meta data-n-head="ssr" data-hid="charset" charset="utf-8"><meta data-n-head="ssr" data-hid="mobile-web-app-capable" name="mobile-web-app-capable" content="yes"><meta data-n-head="ssr" data-hid="apple-mobile-web-app-title" name="apple-mobile-web-app-title" content="filipwieland.com"><meta data-n-head="ssr" data-hid="og:type" name="og:type" property="og:type" content="website"><meta data-n-head="ssr" data-hid="og:title" name="og:title" property="og:title" content="filipwieland.com"><meta data-n-head="ssr" data-hid="og:site_name" name="og:site_name" property="og:site_name" content="filipwieland.com"><meta data-n-head="ssr" data-hid="og:description" name="og:description" property="og:description" content="```bash # install dependencies $ npm install"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link data-n-head="ssr" rel="preconnect" href="https://fonts.gstatic.com"><link data-n-head="ssr" rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@800&family=Roboto+Condensed:ital,wght@0,400;0,700;1,400;1,700&display=swap"><link data-n-head="ssr" rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap"><link data-n-head="ssr" data-hid="shortcut-icon" rel="shortcut icon" href="/_nuxt/icons/icon_64x64.5f6a36.png"><link data-n-head="ssr" data-hid="apple-touch-icon" rel="apple-touch-icon" href="/_nuxt/icons/icon_512x512.5f6a36.png" sizes="512x512"><link data-n-head="ssr" rel="manifest" href="/_nuxt/manifest.8d173111.json" data-hid="manifest"><link rel="preload" href="/_nuxt/ac15482.js" as="script"><link rel="preload" href="/_nuxt/ec2d4cf.js" as="script"><link rel="preload" href="/_nuxt/7b49520.js" as="script"><link rel="preload" href="/_nuxt/34697a2.js" as="script"><link rel="preload" href="/_nuxt/0f58c4a.js" as="script"><style data-vue-ssr-id="4a42b2dc:0 517a8dd7:0 fa7ff0ca:0 215f0c99:0 e3941c4a:0 4f95ad5b:0 2b6482de:0">*,:after,:before{box-sizing:border-box;margin:0}body,html{margin:0;padding:0;font-family:Bahnschrift,"Roboto Condensed",-apple-system,BlinkMacSystemFont,"Helvetica Neue",sans-serif;font-size:14px;font-weight:400;line-height:1.2;background-color:#000;color:#fff}.text-heading,h1,h2,h3,h4,h5,h6{font-family:Montserrat,Bahnschrift,"Roboto Condensed",-apple-system,BlinkMacSystemFont,"Open Sans","Helvetica Neue",sans-serif;font-weight:800;line-height:1.4;margin-bottom:.5em}ol,p,ul{margin-bottom:.5em}ul{padding-left:16px}.__layout,.__nuxt,body,html{height:100%}a{text-decoration:none;color:#db28aa}main a{text-decoration:underline}a:visited{color:#b54e99}a:hover,a:visited:hover{color:#ea7fcd}.text-grey{color:#888}code,kbd,pre,span.text-code,textarea{font-size:14px;line-height:1.2;font-family:"Cascadia Code",Inconsolata,"Source Code Pro",Monaco,Menlo,"Courier New",Courier,monospace}main img{max-width:100%}code[class*=language-],pre[class*=language-]{color:#000;background:0 0;text-shadow:0 1px #fff;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#b3d4fc}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#9a6e3a;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#000;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}.layout-code[data-v-78fadf7c]{background-color:#10007c;height:100vh}.layout-code .layout-inner[data-v-78fadf7c]{padding:16px;height:calc(100% - 48px);overflow:auto}.navbar[data-v-5875e95e]{display:flex;flex-direction:row;background-color:#000;color:#fff;height:48px;align-items:center}.navbar .link-heading-container[data-v-5875e95e]{flex:3}.navbar .link-heading[data-v-5875e95e]{margin-left:16px;color:#fff}.navbar .link-heading[data-v-5875e95e]:hover,.navbar .link-heading[data-v-5875e95e]:visited{color:#fff}.navbar .link-to-theme[data-v-5875e95e]{flex:1;padding:0 16px;height:100%;display:flex;flex-direction:column;justify-content:center;text-align:center}@media screen and (max-width:400px){.navbar .link-to-theme[data-v-5875e95e]{font-size:12px;padding:0 8px}}.link-to-theme[data-v-fba9cf46]{text-decoration:none;text-transform:uppercase}.link-to-theme.theme-code[data-v-fba9cf46]{background-color:#6049ff;color:#e6e2ff}.link-to-theme.theme-code[data-v-fba9cf46]:link{transition:.3s}.link-to-theme.theme-code.active[data-v-fba9cf46],.link-to-theme.theme-code[data-v-fba9cf46]:hover,.link-to-theme.theme-code[data-v-fba9cf46]:visited:hover{color:#fff;background-color:#1d00e2;box-shadow:inset 0 0 5px 2px rgba(16,0,124,.8);transition:.3s}.link-to-theme.theme-code[data-v-fba9cf46]:visited{color:#e6e2ff}.link-to-theme.theme-music[data-v-fba9cf46]{background-color:#1a9e11;color:#64ed5b}.link-to-theme.theme-music[data-v-fba9cf46]:link{transition:.3s}.link-to-theme.theme-music.active[data-v-fba9cf46],.link-to-theme.theme-music[data-v-fba9cf46]:hover,.link-to-theme.theme-music[data-v-fba9cf46]:visited:hover{color:#fff;background-color:#0b4207;box-shadow:inset 0 0 5px 2px rgba(0,0,0,.8);transition:.3s}.link-to-theme.theme-music[data-v-fba9cf46]:visited{color:#64ed5b}.link-to-theme.theme-projects[data-v-fba9cf46]{background-color:#e05c00;color:#ffb17a}.link-to-theme.theme-projects[data-v-fba9cf46]:link{transition:.3s}.link-to-theme.theme-projects.active[data-v-fba9cf46],.link-to-theme.theme-projects[data-v-fba9cf46]:hover,.link-to-theme.theme-projects[data-v-fba9cf46]:visited:hover{color:#fff;background-color:#7a3200;box-shadow:inset 0 0 5px 2px rgba(20,8,0,.8);transition:.3s}.link-to-theme.theme-projects[data-v-fba9cf46]:visited{color:#ffb17a}.link-to-theme .text-heading[data-v-fba9cf46]{margin-bottom:0}.page[data-v-6aae407c]{margin:0 auto;width:100%;max-width:640px}</style><link rel="preload" href="/_nuxt/static/1620063238/code/dril-or-no-dril/state.js" as="script"><link rel="preload" href="/_nuxt/static/1620063238/code/dril-or-no-dril/payload.js" as="script"><link rel="preload" href="/_nuxt/static/1620063238/manifest.js" as="script">
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div class="layout-code" data-v-78fadf7c><div class="navbar" data-v-5875e95e data-v-78fadf7c><div class="link-heading-container" data-v-5875e95e><a href="/" class="text-heading link-heading nuxt-link-active" data-v-5875e95e>Filip Wieland</a></div> <a href="/code" class="link-to-theme nuxt-link-active theme-code active" data-v-fba9cf46 data-v-5875e95e><span class="text-heading" data-v-fba9cf46>
        Code
    </span></a><a href="/music" class="link-to-theme theme-music" data-v-fba9cf46 data-v-5875e95e><span class="text-heading" data-v-fba9cf46>
        Music
    </span></a><a href="/projects" class="link-to-theme theme-projects" data-v-fba9cf46 data-v-5875e95e><span class="text-heading" data-v-fba9cf46>
        Projects
    </span></a></div> <div class="layout-inner" data-v-78fadf7c><div class="page" data-v-6aae407c data-v-78fadf7c><a href="/code" class="nuxt-link-active" data-v-6aae407c>Code <span class="text-grey" data-v-6aae407c>/</span></a> <h1 data-v-6aae407c>Dril Or No Dril? Building a text classifier in TensorFlow</h1> <main data-v-6aae407c><div class="nuxt-content" data-v-6aae407c data-v-6aae407c><p data-v-6aae407c data-v-6aae407c><strong data-v-6aae407c data-v-6aae407c>This post originally appeared on <a href="https://dev.to/minkovsky/dril-or-no-dril-building-a-text-classifier-in-tensorflow-208k" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>dev.to</a></strong></p>

<p data-v-6aae407c data-v-6aae407c>There is a ton of different tensorflow posts on the web already, and many of them are actually good. This is not that. This is me, writing a crappy little classifier for what's essentially an elaborate shitpost.</p>
<p data-v-6aae407c data-v-6aae407c>In this post, I will walk you through how I built <a href="https://dril-or-no-dril.glitch.me/" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>DRIL OR NO DRIL</a>.</p>
<p data-v-6aae407c data-v-6aae407c><img alt='An example of the application in action. A tweet of "no" yields 93.8% dril.' src="https://thepracticaldev.s3.amazonaws.com/i/ijy45dvi3szdtqy9ie2p.png" data-v-6aae407c data-v-6aae407c></p>
<h2 id="overview" data-v-6aae407c data-v-6aae407c><a href="#overview" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Overview</h2>
<p data-v-6aae407c data-v-6aae407c>If you don't know who or what dril is, <a href="https://twitter.com/dril" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>have a look</a>. If you already do, great. If you're just coming back - isn't that one of the weirdest twitter accounts you've seen in a while? Anyway - the style is quite distinctive, so I thought I might have a stab at creating a classifier that tries to pick up on what makes dril <em data-v-6aae407c data-v-6aae407c>dril</em>.</p>
<p data-v-6aae407c data-v-6aae407c>To do that, I first need tweets. Lots of tweets, both from dril and other accounts. I ended up using myself, a few of my friends who agreed to be included in the model, and the Prime Minister (at the time of writing this paragraph, lol) Theresa May.</p>
<p data-v-6aae407c data-v-6aae407c>I also need a model. I ended up using a modified version of the IMDB review classifier from <a href="https://www.tensorflow.org/tutorials/keras/basic_text_classification" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>tensorfow docs</a>.</p>
<p data-v-6aae407c data-v-6aae407c>Finally, to put it online without having to pay for anything, I needed a way to ship my model to the browser with glitch. This also has a bonus of keeping all the text you enter in that box on your machine. I achieved that through tensorflow.js, a browser-based subset of tensorflow which runs on WebGL producing loads of warnings because, really, WebGL wasn't designed to be used this way.</p>
<h2 id="getting-some-tweets" data-v-6aae407c data-v-6aae407c><a href="#getting-some-tweets" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Getting some tweets</h2>
<p data-v-6aae407c data-v-6aae407c>The first thing to do is get some tweets. This requires a Twitter API account so you can authenticate. It's that or doing some screen-scraping hacks but for convenience I stuck with the API - perhaps to my detriment. I wrote a Python script to download all these tweets which was pretty easy thanks to <a href="https://www.tweepy.org/" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>tweepy</a>. It downloads tweets and saves them into a sqlite3 database. It even supports resuming from the earliest downloaded tweet (important in case it crashes). Tweepy's cursor API is also really neat - you can iterate over tweets and it'll handle pagination for you:</p>
<div class="nuxt-content-highlight" data-v-6aae407c data-v-6aae407c><pre class="line-numbers language-python" data-v-6aae407c data-v-6aae407c><code data-v-6aae407c data-v-6aae407c>cursor <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> tweepy<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>Cursor<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>api<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>user_timeline<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> <span class="token builtin" data-v-6aae407c data-v-6aae407c>id</span><span class="token operator" data-v-6aae407c data-v-6aae407c>=</span>args<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>account<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> max_id<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span>max_id<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> include_rts<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token boolean" data-v-6aae407c data-v-6aae407c>False</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>

<span class="token keyword" data-v-6aae407c data-v-6aae407c>for</span> status <span class="token keyword" data-v-6aae407c data-v-6aae407c>in</span> cursor<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>items<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>:</span>
    tweet <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> status_to_tuple<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>status<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
    save_tweet<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>db<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> tweet<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
</code></pre></div>
<p data-v-6aae407c data-v-6aae407c>It's also great that you can tell tweepy to automatically wait in case of a rate-limit response - though I don't think I ran into that issue yet:</p>
<div class="nuxt-content-highlight" data-v-6aae407c data-v-6aae407c><pre class="line-numbers language-python" data-v-6aae407c data-v-6aae407c><code data-v-6aae407c data-v-6aae407c><span class="token keyword" data-v-6aae407c data-v-6aae407c>def</span> <span class="token function" data-v-6aae407c data-v-6aae407c>get_twitter_api</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>:</span>
    auth <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> tweepy<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>OAuthHandler<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>secrets<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>TW_API_KEY<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> secrets<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>TW_API_SECRET<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
    auth<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>set_access_token<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>secrets<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>TW_TOKEN<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> secrets<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>TW_SECRET<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
    <span class="token keyword" data-v-6aae407c data-v-6aae407c>return</span> tweepy<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>API<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>auth<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> wait_on_rate_limit<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token boolean" data-v-6aae407c data-v-6aae407c>True</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> wait_on_rate_limit_notify<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token boolean" data-v-6aae407c data-v-6aae407c>True</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
</code></pre></div>
<p data-v-6aae407c data-v-6aae407c>I then ran the script on some Twitter timelines. I used dril, obviously, as well as some examples of non-dril content. Then I looked at the amount of tweets I downloaded and saw a discrepancy:</p>
<p data-v-6aae407c data-v-6aae407c><img alt="dril's tweet count: 8690 tweets" src="https://thepracticaldev.s3.amazonaws.com/i/iab6wss3n0h9ozifu4f8.png" data-v-6aae407c data-v-6aae407c> <img alt="my dril tweet count in the database: 2930" src="https://thepracticaldev.s3.amazonaws.com/i/j1562o3x0uc03flg9oe1.png" data-v-6aae407c data-v-6aae407c></p>
<p data-v-6aae407c data-v-6aae407c>Turns out that as per <a href="https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>Twitter API docs</a>, the endpoint used only returns up to 3200 most recent tweets. So I guess if you really needed that archival content, you'd have to implement those screen-scraping hacks after all. I chose to not bother.</p>
<h2 id="installing-tensorflow" data-v-6aae407c data-v-6aae407c><a href="#installing-tensorflow" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Installing TensorFlow</h2>
<p data-v-6aae407c data-v-6aae407c>Because this is the real hard problem in computer science (citation needed), I'm now going to spend 5 paragraphs talking about how to install TensorFlow.</p>
<p data-v-6aae407c data-v-6aae407c>j/k, get anaconda and go here: <a href="https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/</a> - works even on exotic platforms such as Windows.</p>
<h2 id="the-classifier" data-v-6aae407c data-v-6aae407c><a href="#the-classifier" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>The classifier</h2>
<p data-v-6aae407c data-v-6aae407c>To create the classifier you will first need to load the data into a format that tensorflow accepts, and there is only one such format - numpy arrays. This is also the first step you will need to make a decision as to how you want to represent the text you put in because you can't simply throw strings at a neural network.</p>
<p data-v-6aae407c data-v-6aae407c>There are a number of ways you could represent a piece of text in a compact way, for instance by using the <a href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>bag-of-words approach</a> which only preserves word frequencies, or by encoding each word as a number as is the case of the TF/Keras IMDB example dataset. You can also try to do fancy things like discarding the most popular words like "a", "the", and "hyperloop is a good idea". In my example I'm not doing any of that and instead I take the raw bytes of each character and shove them into a 240-element numpy array, padding out the remaining space with zeros. The idea is that any other preprocessing could remove nuance about the style of these tweets. Also I'm lazy.</p>
<div class="nuxt-content-highlight" data-v-6aae407c data-v-6aae407c><pre class="line-numbers language-python" data-v-6aae407c data-v-6aae407c><code data-v-6aae407c data-v-6aae407c><span class="token keyword" data-v-6aae407c data-v-6aae407c>def</span> <span class="token function" data-v-6aae407c data-v-6aae407c>to_padded_bytes</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>tweet<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>:</span>
    bts <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> np<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>array<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>[</span><span class="token builtin" data-v-6aae407c data-v-6aae407c>ord</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>c<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span> <span class="token keyword" data-v-6aae407c data-v-6aae407c>for</span> c <span class="token keyword" data-v-6aae407c data-v-6aae407c>in</span> tweet<span class="token punctuation" data-v-6aae407c data-v-6aae407c>]</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
    <span class="token keyword" data-v-6aae407c data-v-6aae407c>return</span> np<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>pad<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>bts<span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> <span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token number" data-v-6aae407c data-v-6aae407c>0</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> <span class="token number" data-v-6aae407c data-v-6aae407c>240</span> <span class="token operator" data-v-6aae407c data-v-6aae407c>-</span> bts<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>shape<span class="token punctuation" data-v-6aae407c data-v-6aae407c>[</span><span class="token number" data-v-6aae407c data-v-6aae407c>0</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>]</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> mode<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token string" data-v-6aae407c data-v-6aae407c>'constant'</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
</code></pre></div>
<p data-v-6aae407c data-v-6aae407c>This still meant that I needed to have an embedding layer in my network that extracted features from the byte values, but it was a little bit different than in the example.</p>
<p data-v-6aae407c data-v-6aae407c>Finally, the labels are represented as 2-dimensional vectors. A dril tweet is labelled as <code data-v-6aae407c data-v-6aae407c>[1, 0]</code>, whereas a non-dril tweet is <code data-v-6aae407c data-v-6aae407c>[0, 1]</code>. This is so that at the end of the process I can get the confidence value from the network - it will usually reply with a vector like <code data-v-6aae407c data-v-6aae407c>[0.98, 0.02]</code> which means "I am 90% confident that this is a dril tweet and only 2% confident that it's not". Or the inverse. Or somewhere in between.</p>
<p data-v-6aae407c data-v-6aae407c>The model itself is as follows:</p>
<div class="nuxt-content-highlight" data-v-6aae407c data-v-6aae407c><pre class="line-numbers language-python" data-v-6aae407c data-v-6aae407c><code data-v-6aae407c data-v-6aae407c>model <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> keras<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>Sequential<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>[</span>
    keras<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>layers<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>Embedding<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token number" data-v-6aae407c data-v-6aae407c>255</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> <span class="token number" data-v-6aae407c data-v-6aae407c>16</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> input_length<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token number" data-v-6aae407c data-v-6aae407c>240</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span>
    keras<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>layers<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>Conv1D<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token number" data-v-6aae407c data-v-6aae407c>140</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> <span class="token number" data-v-6aae407c data-v-6aae407c>3</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> padding<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token string" data-v-6aae407c data-v-6aae407c>'valid'</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> activation<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token string" data-v-6aae407c data-v-6aae407c>'relu'</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> strides<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token number" data-v-6aae407c data-v-6aae407c>1</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span>
    keras<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>layers<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>GlobalAveragePooling1D<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span>
    keras<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>layers<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>Dense<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token number" data-v-6aae407c data-v-6aae407c>512</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> activation<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token string" data-v-6aae407c data-v-6aae407c>'relu'</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span>
    keras<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>layers<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span>Dense<span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token number" data-v-6aae407c data-v-6aae407c>2</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> activation<span class="token operator" data-v-6aae407c data-v-6aae407c>=</span><span class="token string" data-v-6aae407c data-v-6aae407c>'softmax'</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
<span class="token punctuation" data-v-6aae407c data-v-6aae407c>]</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span>
</code></pre></div>
<p data-v-6aae407c data-v-6aae407c>I threw in the convolutional stage because I'm hoping it's able to pick up on the stylistic differences between types of tweeter, but so far it's mostly learned that shorter tweets are more likely to be dril, and that he doesn't use emoji very often. Nonetheless, at ~89% validation accuracy, I decided that it's good enough for a joke.</p>
<p data-v-6aae407c data-v-6aae407c>If I were doing this properly I might look at existing text classification architectures and try to actually learn something from them. Then maybe I'd achieve that 99% accuracy.</p>
<h2 id="onwards-to-javascript" data-v-6aae407c data-v-6aae407c><a href="#onwards-to-javascript" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Onwards to JavaScript</h2>
<p data-v-6aae407c data-v-6aae407c>tensorflow.js is a little limited. From the <a href="https://js.tensorflow.org/tutorials/import-keras.html" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>docs</a>:</p>
<blockquote data-v-6aae407c data-v-6aae407c>
<p data-v-6aae407c data-v-6aae407c>TensorFlow.js Layers currently only supports Keras models using standard Keras constructs. Models using unsupported ops or layers—e.g. custom layers, Lambda layers, custom losses, or custom metrics—cannot be automatically imported, because they depend on Python code that cannot be reliably translated into JavaScript.</p>
</blockquote>
<p data-v-6aae407c data-v-6aae407c>That's fine though, as my model <em data-v-6aae407c data-v-6aae407c>is</em> only using standard constructs. The first step is to save it to a h5 file, then you can run the tensorflowjs converter on it. To get the converter, you can run <code data-v-6aae407c data-v-6aae407c>pip install tensorflowjs</code> in your conda environment. Note, though, that some of the installed packages might get downgraded as the dependencies are a little out of sync - this shouldn't be too worrying as they are all within requirements of each other. The converter will generate a directory with two or more files: a <code data-v-6aae407c data-v-6aae407c>model.json</code> file which describes the structure of the model, and some <code data-v-6aae407c data-v-6aae407c>groupK-shardNofM</code> files which contain the learned attributes of your model (the weights, in the ML lingo). You can then serve these files from a web server and load them on the client side like so:</p>
<div class="nuxt-content-highlight" data-v-6aae407c data-v-6aae407c><pre class="line-numbers language-javascript" data-v-6aae407c data-v-6aae407c><code data-v-6aae407c data-v-6aae407c><span class="token comment" data-v-6aae407c data-v-6aae407c>// This assumes that model.json is in the same directory as the current document</span>
<span class="token keyword" data-v-6aae407c data-v-6aae407c>const</span> model <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> <span class="token keyword control-flow" data-v-6aae407c data-v-6aae407c>await</span> tf<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token method function property-access" data-v-6aae407c data-v-6aae407c>loadModel</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token string" data-v-6aae407c data-v-6aae407c>'model.json'</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
</code></pre></div>
<p data-v-6aae407c data-v-6aae407c>If you don't know what the <code data-v-6aae407c data-v-6aae407c>await</code> does, read this: <a href="https://ponyfoo.com/articles/understanding-javascript-async-await" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>https://ponyfoo.com/articles/understanding-javascript-async-await</a>. If you do and are positive you can't use it, it's still a promise so you can work with that instead. If you need to support Internet Explorer, ask your doctor if tensorflow.js is right for you. In my case I decided that being compatible with popular browsers is for losers and just use async/await as they are.</p>
<p data-v-6aae407c data-v-6aae407c>The glitch project itself is also very simple - the main issue is getting the text from a <code data-v-6aae407c data-v-6aae407c>&lt;textarea></code> into the same format as I used in training, namely a 1x240 tensor. The code is pretty similar to the python version:</p>
<div class="nuxt-content-highlight" data-v-6aae407c data-v-6aae407c><pre class="line-numbers language-javascript" data-v-6aae407c data-v-6aae407c><code data-v-6aae407c data-v-6aae407c><span class="token keyword" data-v-6aae407c data-v-6aae407c>function</span> <span class="token function" data-v-6aae407c data-v-6aae407c>tweetToTensor</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token parameter" data-v-6aae407c data-v-6aae407c>tweet</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span> <span class="token punctuation" data-v-6aae407c data-v-6aae407c>{</span>
  <span class="token keyword" data-v-6aae407c data-v-6aae407c>const</span> array <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> <span class="token keyword" data-v-6aae407c data-v-6aae407c>new</span> <span class="token class-name" data-v-6aae407c data-v-6aae407c>Uint8Array</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token number" data-v-6aae407c data-v-6aae407c>240</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
  <span class="token keyword control-flow" data-v-6aae407c data-v-6aae407c>for</span> <span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token keyword" data-v-6aae407c data-v-6aae407c>let</span> i <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> <span class="token number" data-v-6aae407c data-v-6aae407c>0</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span> i <span class="token operator" data-v-6aae407c data-v-6aae407c>&lt;</span> tweet<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token property-access" data-v-6aae407c data-v-6aae407c>length</span> <span class="token operator" data-v-6aae407c data-v-6aae407c>&&</span> i <span class="token operator" data-v-6aae407c data-v-6aae407c>&lt;</span> array<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token property-access" data-v-6aae407c data-v-6aae407c>length</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span> i<span class="token operator" data-v-6aae407c data-v-6aae407c>++</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span> <span class="token punctuation" data-v-6aae407c data-v-6aae407c>{</span>
    array<span class="token punctuation" data-v-6aae407c data-v-6aae407c>[</span>i<span class="token punctuation" data-v-6aae407c data-v-6aae407c>]</span> <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> tweet<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token method function property-access" data-v-6aae407c data-v-6aae407c>charCodeAt</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>i<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
  <span class="token punctuation" data-v-6aae407c data-v-6aae407c>}</span>
  <span class="token keyword control-flow" data-v-6aae407c data-v-6aae407c>return</span> tf<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token method function property-access" data-v-6aae407c data-v-6aae407c>tensor1d</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>array<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
<span class="token punctuation" data-v-6aae407c data-v-6aae407c>}</span>

<span class="token comment" data-v-6aae407c data-v-6aae407c>// later...</span>

<span class="token keyword" data-v-6aae407c data-v-6aae407c>const</span> batch <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> <span class="token function" data-v-6aae407c data-v-6aae407c>tweetToTensor</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>text<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token method function property-access" data-v-6aae407c data-v-6aae407c>reshape</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>[</span><span class="token number" data-v-6aae407c data-v-6aae407c>1</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>,</span> <span class="token number" data-v-6aae407c data-v-6aae407c>240</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>]</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
<span class="token keyword" data-v-6aae407c data-v-6aae407c>const</span> prediction <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> model<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token method function property-access" data-v-6aae407c data-v-6aae407c>predict</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span>batch<span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
<span class="token keyword" data-v-6aae407c data-v-6aae407c>const</span> result <span class="token operator" data-v-6aae407c data-v-6aae407c>=</span> prediction<span class="token punctuation" data-v-6aae407c data-v-6aae407c>.</span><span class="token method function property-access" data-v-6aae407c data-v-6aae407c>reshape</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>(</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>[</span><span class="token number" data-v-6aae407c data-v-6aae407c>2</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>]</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>)</span><span class="token punctuation" data-v-6aae407c data-v-6aae407c>;</span>
</code></pre></div>
<p data-v-6aae407c data-v-6aae407c>It's nice that I don't have to explicitly pad out my arrays here because allocating a <code data-v-6aae407c data-v-6aae407c>Uint8Array</code> automatically gives me a zero'd-out array so I only need to copy in the relevant byte values.</p>
<p data-v-6aae407c data-v-6aae407c>There is one issue with hosting everything on glitch though - since the <code data-v-6aae407c data-v-6aae407c>group-shard-piece-whatever</code> files are binary, glitch uploads them to a cdn and gives you a long link to the file in its bucket. This is fine for images, but tensorflow.js expects that it'll be able to get the weights files from the same base URL as the model.json file (eg. if the model file is at <code data-v-6aae407c data-v-6aae407c>https://example.com/models/model.json</code>, it'll look for files like <code data-v-6aae407c data-v-6aae407c>https://example.com/models/group1-shard1of1</code> etc). However, since the library uses <code data-v-6aae407c data-v-6aae407c>fetch()</code>, it also follows redirects, and it's easy to set up your server script to catch requests for the weights files and point it to the right place.</p>
<p data-v-6aae407c data-v-6aae407c>Well, easy if you've got one or two files; if you need more than that, again ask your doctor if tensorflow.js and glitch are right for you.</p>
<h2 id="wheres-the-code" data-v-6aae407c data-v-6aae407c><a href="#wheres-the-code" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Where's the code?</h2>
<p data-v-6aae407c data-v-6aae407c>The classifier etc: <a href="https://github.com/FLamparski/dril-or-no-dril/blob/master/Dril%20Or%20No%20Dril.ipynb" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>https://github.com/FLamparski/dril-or-no-dril/blob/master/Dril%20Or%20No%20Dril.ipynb</a> - the same repo also contains the tweet download scripts, but you'll need to provide your own <code data-v-6aae407c data-v-6aae407c>secrets.py</code> file.</p>
<p data-v-6aae407c data-v-6aae407c>The glitch site: <a href="https://glitch.com/edit/#!/dril-or-no-dril" rel="nofollow noopener noreferrer" target="_blank" data-v-6aae407c data-v-6aae407c>https://glitch.com/edit/#!/dril-or-no-dril</a></p>
<h2 id="learnings" data-v-6aae407c data-v-6aae407c><a href="#learnings" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Learnings</h2>
<p data-v-6aae407c data-v-6aae407c>From what's essentially an elaborate joke, I learned a thing or two about conducting machine learning experiments on data that wasn't delivered to you in a neatly wrapped package with instructions. It's a harsh world out there and most data will be messy and in the wrong format. About 2/3 (or more, haven't checked) of the code I wrote deals with acquiring the data and preparing it for the model. If I was to do this again <em data-v-6aae407c data-v-6aae407c>properly</em>, I might also look into ways of getting past that Twitter API tweet limit, and gathered up much more non-dril material. As it stands, the classifier is biased towards saying the input is dril-like. I would definitely look at different text processing models, both in terms of how the neural network is actually designed, and how to encode the data going into it. The vector-of-bytes idea is not terribly efficient and would not scale well to longer documents. I might even be tempted to try and serve this model from an actual server instead of dumping it into the user's browser in hopes that it'll work (those weights files can get awfully large sometimes...). I hear that Google has an offering for production machine learning apps. Or something.</p>
<h2 id="discussion" data-v-6aae407c data-v-6aae407c><a href="#discussion" aria-hidden="true" tabindex="-1" data-v-6aae407c data-v-6aae407c><span class="icon icon-link" data-v-6aae407c data-v-6aae407c></span></a>Discussion</h2>
<p data-v-6aae407c data-v-6aae407c>I'd like to hear from you if you have an idea of what you'd do for an application like that, especially if what you'd do is different and actually works. I'd also like to know what's the silliest machine learning thing you've made, and whether you went through the trouble of putting it online.</p>
<p data-v-6aae407c data-v-6aae407c>Right, until next time!</p></div></main></div></div></div></div></div><script defer src="/_nuxt/static/1620063238/code/dril-or-no-dril/state.js"></script><script src="/_nuxt/ac15482.js" defer></script><script src="/_nuxt/0f58c4a.js" defer></script><script src="/_nuxt/ec2d4cf.js" defer></script><script src="/_nuxt/7b49520.js" defer></script><script src="/_nuxt/34697a2.js" defer></script>
  </body>
</html>
